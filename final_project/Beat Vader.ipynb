{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import GetOldTweets3 as got\n",
    "import warnings\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 1000\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actual, pred):\n",
    "    true = 0\n",
    "    for i in range(len(pred)):\n",
    "        if actual[i] == round(pred[i]):\n",
    "            true +=1\n",
    "    return true/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(tweet):\n",
    "    tweet = tweet.split()\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    lemmed = [stemmer.lemmatize(word) for word in tweet]\n",
    "    return ' '.join(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(score):\n",
    "    if score > .05:\n",
    "        return 1\n",
    "    elif score < -.05:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', text)\n",
    "    text = re.sub('@[^\\s]+', '', text)\n",
    "    text = re.sub('#([^\\s]+)', '', text)\n",
    "    text = regex.sub('', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data and doing some preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Tweets_airline.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['airline_sentiment'] = train['airline_sentiment'].replace('neutral', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['airline_sentiment'] = train['airline_sentiment'].replace('positive', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['airline_sentiment'] = train['airline_sentiment'].replace('negative', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].map(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train['airline_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines and parameter grids to search over for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0        0.303325      0.005662         0.078946        0.005677        0.01   \n",
      "1        0.413327      0.002704         0.077473        0.004916        0.01   \n",
      "2        0.481036      0.011645         0.083784        0.000687        0.01   \n",
      "3        0.287553      0.004664         0.083721        0.003472        0.01   \n",
      "4        0.421319      0.006690         0.086509        0.002552         0.1   \n",
      "5        0.380386      0.010134         0.083227        0.003345         0.1   \n",
      "6        0.473656      0.009565         0.083408        0.006640         0.1   \n",
      "7        0.381925      0.009643         0.084027        0.001767         0.1   \n",
      "8        0.433538      0.010262         0.083662        0.008754         0.5   \n",
      "9        0.441913      0.014785         0.084766        0.005601         0.5   \n",
      "10       0.493259      0.021914         0.084745        0.003772         0.5   \n",
      "11       0.511842      0.041618         0.081705        0.004400         0.5   \n",
      "12       0.490767      0.015844         0.084514        0.003016           1   \n",
      "13       0.410374      0.038395         0.086326        0.015189           1   \n",
      "14       0.481008      0.037616         0.066239        0.007455           1   \n",
      "15       0.531845      0.041967         0.075333        0.009667           1   \n",
      "\n",
      "   param_lr__solver                                      params  \\\n",
      "0         newton-cg  {'lr__C': 0.01, 'lr__solver': 'newton-cg'}   \n",
      "1               sag        {'lr__C': 0.01, 'lr__solver': 'sag'}   \n",
      "2              saga       {'lr__C': 0.01, 'lr__solver': 'saga'}   \n",
      "3             lbfgs      {'lr__C': 0.01, 'lr__solver': 'lbfgs'}   \n",
      "4         newton-cg   {'lr__C': 0.1, 'lr__solver': 'newton-cg'}   \n",
      "5               sag         {'lr__C': 0.1, 'lr__solver': 'sag'}   \n",
      "6              saga        {'lr__C': 0.1, 'lr__solver': 'saga'}   \n",
      "7             lbfgs       {'lr__C': 0.1, 'lr__solver': 'lbfgs'}   \n",
      "8         newton-cg   {'lr__C': 0.5, 'lr__solver': 'newton-cg'}   \n",
      "9               sag         {'lr__C': 0.5, 'lr__solver': 'sag'}   \n",
      "10             saga        {'lr__C': 0.5, 'lr__solver': 'saga'}   \n",
      "11            lbfgs       {'lr__C': 0.5, 'lr__solver': 'lbfgs'}   \n",
      "12        newton-cg     {'lr__C': 1, 'lr__solver': 'newton-cg'}   \n",
      "13              sag           {'lr__C': 1, 'lr__solver': 'sag'}   \n",
      "14             saga          {'lr__C': 1, 'lr__solver': 'saga'}   \n",
      "15            lbfgs         {'lr__C': 1, 'lr__solver': 'lbfgs'}   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
      "0            0.630156           0.630328           0.630227         0.630237   \n",
      "1            0.630156           0.630328           0.630227         0.630237   \n",
      "2            0.630156           0.630328           0.630227         0.630237   \n",
      "3            0.630156           0.630328           0.630227         0.630237   \n",
      "4            0.670309           0.667486           0.670948         0.669581   \n",
      "5            0.670309           0.667486           0.670948         0.669581   \n",
      "6            0.670309           0.667486           0.670948         0.669581   \n",
      "7            0.670309           0.667486           0.670948         0.669581   \n",
      "8            0.721114           0.724863           0.731074         0.725683   \n",
      "9            0.721114           0.724863           0.731074         0.725683   \n",
      "10           0.721388           0.724863           0.731621         0.725956   \n",
      "11           0.721114           0.724863           0.730801         0.725592   \n",
      "12           0.750068           0.750273           0.746652         0.748998   \n",
      "13           0.750068           0.750273           0.746652         0.748998   \n",
      "14           0.750068           0.750546           0.746379         0.748998   \n",
      "15           0.750068           0.750273           0.746652         0.748998   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.000071               13            0.630277            0.630191   \n",
      "1         0.000071               13            0.630277            0.630191   \n",
      "2         0.000071               13            0.630277            0.630191   \n",
      "3         0.000071               13            0.630277            0.630191   \n",
      "4         0.001504                9            0.668671            0.671311   \n",
      "5         0.001504                9            0.668671            0.671311   \n",
      "6         0.001504                9            0.668671            0.671585   \n",
      "7         0.001504                9            0.668671            0.671311   \n",
      "8         0.004107                6            0.756797            0.753689   \n",
      "9         0.004107                6            0.756797            0.753689   \n",
      "10        0.004249                5            0.757071            0.753689   \n",
      "11        0.003988                8            0.756797            0.753689   \n",
      "12        0.001661                1            0.824566            0.820765   \n",
      "13        0.001661                1            0.824566            0.820765   \n",
      "14        0.001862                1            0.824566            0.821038   \n",
      "15        0.001661                1            0.824566            0.820765   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             0.630242          0.630237         0.000035  \n",
      "1             0.630242          0.630237         0.000035  \n",
      "2             0.630242          0.630237         0.000035  \n",
      "3             0.630242          0.630237         0.000035  \n",
      "4             0.670400          0.670127         0.001095  \n",
      "5             0.670400          0.670127         0.001095  \n",
      "6             0.670400          0.670219         0.001197  \n",
      "7             0.670400          0.670127         0.001095  \n",
      "8             0.757957          0.756147         0.001802  \n",
      "9             0.757957          0.756147         0.001802  \n",
      "10            0.758640          0.756466         0.002066  \n",
      "11            0.757957          0.756147         0.001802  \n",
      "12            0.829122          0.824818         0.003416  \n",
      "13            0.829122          0.824818         0.003416  \n",
      "14            0.828985          0.824863         0.003251  \n",
      "15            0.829122          0.824818         0.003416  \n"
     ]
    }
   ],
   "source": [
    "parameters_lr = {\n",
    "    'lr__C': (.01,0.1, 0.5,1),\n",
    "    'lr__solver' : ('newton-cg', 'sag', 'saga', 'lbfgs')\n",
    "}\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('lr', LogisticRegression(max_iter = 400))\n",
    "])\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, parameters_lr, cv = 3)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "results_lr = pd.DataFrame.from_dict(grid_lr.cv_results_)\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0        0.287868      0.038684         0.054824        0.008836        0.01   \n",
      "1        0.238169      0.010564         0.064181        0.008008        0.01   \n",
      "2        0.991711      0.389782         0.078524        0.025684        0.01   \n",
      "3        0.266873      0.036013         0.085512        0.019144        0.01   \n",
      "4        0.453303      0.007257         0.087080        0.013331         0.1   \n",
      "5        0.528335      0.031771         0.080835        0.003755         0.1   \n",
      "6        1.059944      0.117705         0.082921        0.013470         0.1   \n",
      "7        0.342139      0.032617         0.082172        0.014567         0.1   \n",
      "8        0.545696      0.028041         0.070883        0.003793         0.5   \n",
      "9        0.654355      0.081748         0.096409        0.027061         0.5   \n",
      "10       1.328736      0.086946         0.084531        0.010781         0.5   \n",
      "11       0.389565      0.011762         0.075182        0.006972         0.5   \n",
      "12       0.611476      0.050534         0.087509        0.011526           1   \n",
      "13       0.903160      0.123977         0.103096        0.007875           1   \n",
      "14       1.838497      0.218493         0.093627        0.007587           1   \n",
      "15       0.570470      0.009463         0.087228        0.003441           1   \n",
      "\n",
      "   param_lr__solver                                      params  \\\n",
      "0         newton-cg  {'lr__C': 0.01, 'lr__solver': 'newton-cg'}   \n",
      "1               sag        {'lr__C': 0.01, 'lr__solver': 'sag'}   \n",
      "2              saga       {'lr__C': 0.01, 'lr__solver': 'saga'}   \n",
      "3             lbfgs      {'lr__C': 0.01, 'lr__solver': 'lbfgs'}   \n",
      "4         newton-cg   {'lr__C': 0.1, 'lr__solver': 'newton-cg'}   \n",
      "5               sag         {'lr__C': 0.1, 'lr__solver': 'sag'}   \n",
      "6              saga        {'lr__C': 0.1, 'lr__solver': 'saga'}   \n",
      "7             lbfgs       {'lr__C': 0.1, 'lr__solver': 'lbfgs'}   \n",
      "8         newton-cg   {'lr__C': 0.5, 'lr__solver': 'newton-cg'}   \n",
      "9               sag         {'lr__C': 0.5, 'lr__solver': 'sag'}   \n",
      "10             saga        {'lr__C': 0.5, 'lr__solver': 'saga'}   \n",
      "11            lbfgs       {'lr__C': 0.5, 'lr__solver': 'lbfgs'}   \n",
      "12        newton-cg     {'lr__C': 1, 'lr__solver': 'newton-cg'}   \n",
      "13              sag           {'lr__C': 1, 'lr__solver': 'sag'}   \n",
      "14             saga          {'lr__C': 1, 'lr__solver': 'saga'}   \n",
      "15            lbfgs         {'lr__C': 1, 'lr__solver': 'lbfgs'}   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
      "0            0.671128           0.668033           0.674775         0.671311   \n",
      "1            0.671128           0.668033           0.674775         0.671311   \n",
      "2            0.671128           0.668033           0.675048         0.671403   \n",
      "3            0.671128           0.668033           0.674775         0.671311   \n",
      "4            0.737777           0.740984           0.743373         0.740710   \n",
      "5            0.737777           0.740984           0.743373         0.740710   \n",
      "6            0.738323           0.740710           0.743919         0.740984   \n",
      "7            0.737777           0.740984           0.743373         0.740710   \n",
      "8            0.771101           0.767760           0.760044         0.766302   \n",
      "9            0.771101           0.767760           0.760044         0.766302   \n",
      "10           0.770281           0.767760           0.759770         0.765938   \n",
      "11           0.771101           0.767760           0.760044         0.766302   \n",
      "12           0.773286           0.769945           0.759224         0.767486   \n",
      "13           0.773286           0.769945           0.759224         0.767486   \n",
      "14           0.773286           0.769126           0.758951         0.767122   \n",
      "15           0.773286           0.769945           0.759224         0.767486   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.002755               14            0.672360            0.676503   \n",
      "1         0.002755               14            0.672360            0.676503   \n",
      "2         0.002870               13            0.673043            0.677596   \n",
      "3         0.002755               14            0.672360            0.676503   \n",
      "4         0.002293               10            0.774423            0.773497   \n",
      "5         0.002293               10            0.774423            0.773497   \n",
      "6         0.002293                9            0.774559            0.774317   \n",
      "7         0.002293               10            0.774423            0.773497   \n",
      "8         0.004630                5            0.841508            0.836749   \n",
      "9         0.004630                5            0.841508            0.836749   \n",
      "10        0.004480                8            0.840962            0.836885   \n",
      "11        0.004630                5            0.841508            0.836749   \n",
      "12        0.005998                1            0.859817            0.854235   \n",
      "13        0.005998                1            0.859817            0.853962   \n",
      "14        0.006021                4            0.859817            0.854372   \n",
      "15        0.005998                1            0.859817            0.854098   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             0.672176          0.673679         0.001998  \n",
      "1             0.672176          0.673679         0.001998  \n",
      "2             0.672722          0.674454         0.002226  \n",
      "3             0.672176          0.673679         0.001998  \n",
      "4             0.780221          0.776047         0.002976  \n",
      "5             0.780221          0.776047         0.002976  \n",
      "6             0.780085          0.776320         0.002664  \n",
      "7             0.780221          0.776047         0.002976  \n",
      "8             0.841961          0.840073         0.002358  \n",
      "9             0.842098          0.840118         0.002395  \n",
      "10            0.842644          0.840164         0.002418  \n",
      "11            0.841961          0.840073         0.002358  \n",
      "12            0.859445          0.857832         0.002548  \n",
      "13            0.859445          0.857741         0.002677  \n",
      "14            0.859445          0.857878         0.002484  \n",
      "15            0.859445          0.857787         0.002613  \n"
     ]
    }
   ],
   "source": [
    "parameters_lr = {\n",
    "    'lr__C': (.01,0.1, 0.5,1),\n",
    "    'lr__solver' : ('newton-cg', 'sag', 'saga', 'lbfgs')\n",
    "}\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english')  ),\n",
    "    ('lr', LogisticRegression(max_iter = 400))\n",
    "])\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, parameters_lr, cv = 3)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "results_lr = pd.DataFrame.from_dict(grid_lr.cv_results_)\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate best LR model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580081</td>\n",
       "      <td>0.633824</td>\n",
       "      <td>0.534739</td>\n",
       "      <td>806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672582</td>\n",
       "      <td>0.713748</td>\n",
       "      <td>0.635906</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857871</td>\n",
       "      <td>0.824418</td>\n",
       "      <td>0.894154</td>\n",
       "      <td>2258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.772951</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.703511</td>\n",
       "      <td>0.723996</td>\n",
       "      <td>0.688267</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.766524</td>\n",
       "      <td>0.764424</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.580081   0.633824  0.534739    806.0\n",
       "1             0.672582   0.713748  0.635906    596.0\n",
       "2             0.857871   0.824418  0.894154   2258.0\n",
       "micro avg     0.772951   0.772951  0.772951   3660.0\n",
       "macro avg     0.703511   0.723996  0.688267   3660.0\n",
       "weighted avg  0.766524   0.764424  0.772951   3660.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_lr = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english')  ),\n",
    "    ('lr', LogisticRegression( C = 1, solver = 'saga',max_iter = 400))\n",
    "])\n",
    "\n",
    "best_pipeline_lr.fit(X_train, y_train)\n",
    "best_lr_preds = best_pipeline_lr.predict(X_test)\n",
    "\n",
    "cr_best_lr = classification_report(y_test,best_lr_preds,output_dict=True)\n",
    "pd.DataFrame(cr_best_lr).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines and parameter grids to search over for naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.109253      0.007952         0.043700        0.005418   \n",
      "1       0.103535      0.005379         0.044257        0.005766   \n",
      "2       0.106139      0.013787         0.053318        0.001405   \n",
      "3       0.100632      0.003447         0.046944        0.003195   \n",
      "4       0.120600      0.019182         0.056550        0.009661   \n",
      "5       0.114895      0.013103         0.050716        0.006792   \n",
      "\n",
      "  param_nb__alpha param_nb__fit_prior  \\\n",
      "0           1e-05                True   \n",
      "1           1e-05               False   \n",
      "2             0.5                True   \n",
      "3             0.5               False   \n",
      "4               1                True   \n",
      "5               1               False   \n",
      "\n",
      "                                         params  split0_test_score  \\\n",
      "0   {'nb__alpha': 1e-05, 'nb__fit_prior': True}           0.707457   \n",
      "1  {'nb__alpha': 1e-05, 'nb__fit_prior': False}           0.699809   \n",
      "2     {'nb__alpha': 0.5, 'nb__fit_prior': True}           0.702267   \n",
      "3    {'nb__alpha': 0.5, 'nb__fit_prior': False}           0.756078   \n",
      "4       {'nb__alpha': 1, 'nb__fit_prior': True}           0.679596   \n",
      "5      {'nb__alpha': 1, 'nb__fit_prior': False}           0.747883   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.718033           0.713036         0.712842        0.004320   \n",
      "1           0.704372           0.694452         0.699545        0.004054   \n",
      "2           0.702459           0.704291         0.703005        0.000912   \n",
      "3           0.760929           0.749385         0.755464        0.004732   \n",
      "4           0.676503           0.680241         0.678780        0.001631   \n",
      "5           0.752732           0.748565         0.749727        0.002143   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                3            0.917338            0.919945   \n",
      "1                5            0.931275            0.931011   \n",
      "2                4            0.811860            0.806284   \n",
      "3                1            0.885640            0.886066   \n",
      "4                6            0.739992            0.736749   \n",
      "5                2            0.858041            0.861066   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.920912          0.919399         0.001509  \n",
      "1            0.937987          0.933424         0.003228  \n",
      "2            0.812457          0.810200         0.002780  \n",
      "3            0.890589          0.887431         0.002239  \n",
      "4            0.733233          0.736658         0.002760  \n",
      "5            0.864226          0.861111         0.002525  \n"
     ]
    }
   ],
   "source": [
    "parameters_nb = {\n",
    "    'nb__alpha': (0.00001, 0.5, 1),\n",
    "    'nb__fit_prior' : (True, False)\n",
    "}\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "grid_nb = GridSearchCV(pipeline_nb, parameters_nb, cv = 3)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "results_nb = pd.DataFrame.from_dict(grid_nb.cv_results_)\n",
    "print(results_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.114632      0.009994         0.045163        0.005376   \n",
      "1       0.130548      0.009923         0.059124        0.015030   \n",
      "2       0.139077      0.013787         0.057653        0.006865   \n",
      "3       0.117761      0.010797         0.053411        0.010458   \n",
      "4       0.180616      0.010473         0.094216        0.010771   \n",
      "5       0.204002      0.006947         0.092391        0.002514   \n",
      "\n",
      "  param_nb__alpha param_nb__fit_prior  \\\n",
      "0           1e-05                True   \n",
      "1           1e-05               False   \n",
      "2             0.5                True   \n",
      "3             0.5               False   \n",
      "4               1                True   \n",
      "5               1               False   \n",
      "\n",
      "                                         params  split0_test_score  \\\n",
      "0   {'nb__alpha': 1e-05, 'nb__fit_prior': True}           0.731494   \n",
      "1  {'nb__alpha': 1e-05, 'nb__fit_prior': False}           0.709096   \n",
      "2     {'nb__alpha': 0.5, 'nb__fit_prior': True}           0.742420   \n",
      "3    {'nb__alpha': 0.5, 'nb__fit_prior': False}           0.716744   \n",
      "4       {'nb__alpha': 1, 'nb__fit_prior': True}           0.740781   \n",
      "5      {'nb__alpha': 1, 'nb__fit_prior': False}           0.716198   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.733607           0.737087         0.734062        0.002306   \n",
      "1           0.709290           0.714676         0.711020        0.002586   \n",
      "2           0.743989           0.746925         0.744444        0.001867   \n",
      "3           0.716120           0.720415         0.717760        0.001895   \n",
      "4           0.743169           0.745832         0.743260        0.002063   \n",
      "5           0.715847           0.717136         0.716393        0.000544   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                3            0.825796            0.823361   \n",
      "1                6            0.809127            0.806557   \n",
      "2                1            0.813362            0.811339   \n",
      "3                4            0.787813            0.782377   \n",
      "4                2            0.805165            0.804098   \n",
      "5                5            0.779615            0.773361   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.824204          0.824454         0.001010  \n",
      "1            0.805354          0.807013         0.001573  \n",
      "2            0.813687          0.812796         0.001039  \n",
      "3            0.782134          0.784108         0.002622  \n",
      "4            0.806994          0.805419         0.001196  \n",
      "5            0.776943          0.776639         0.002562  \n"
     ]
    }
   ],
   "source": [
    "parameters_nb = {\n",
    "    'nb__alpha': (0.00001, 0.5, 1),\n",
    "    'nb__fit_prior' : (True, False)\n",
    "}\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english') ),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "grid_nb = GridSearchCV(pipeline_nb, parameters_nb, cv = 3)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "results_nb = pd.DataFrame.from_dict(grid_nb.cv_results_)\n",
    "print(results_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate best NB model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.550642</td>\n",
       "      <td>0.647651</td>\n",
       "      <td>0.478908</td>\n",
       "      <td>806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.656557</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.910983</td>\n",
       "      <td>2258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.768033</td>\n",
       "      <td>0.768033</td>\n",
       "      <td>0.768033</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.688273</td>\n",
       "      <td>0.719588</td>\n",
       "      <td>0.669114</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.757276</td>\n",
       "      <td>0.756590</td>\n",
       "      <td>0.768033</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.550642   0.647651  0.478908    806.0\n",
       "1             0.656557   0.700952  0.617450    596.0\n",
       "2             0.857619   0.810161  0.910983   2258.0\n",
       "micro avg     0.768033   0.768033  0.768033   3660.0\n",
       "macro avg     0.688273   0.719588  0.669114   3660.0\n",
       "weighted avg  0.757276   0.756590  0.768033   3660.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('nb', MultinomialNB(alpha = .5, fit_prior = False))\n",
    "])\n",
    "\n",
    "best_pipeline_nb.fit(X_train, y_train)\n",
    "best_nb_preds = best_pipeline_nb.predict(X_test)\n",
    "\n",
    "cr_best_nb = classification_report(y_test,best_nb_preds,output_dict=True)\n",
    "pd.DataFrame(cr_best_nb).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines and parameter grids to search over for adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       3.124988      0.122759         0.549275        0.035159   \n",
      "1       6.496741      0.185280         0.986089        0.071680   \n",
      "\n",
      "  param_ada__n_estimators                       params  split0_test_score  \\\n",
      "0                     500   {'ada__n_estimators': 500}           0.738050   \n",
      "1                    1000  {'ada__n_estimators': 1000}           0.720841   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.739344           0.727521         0.734973        0.005294   \n",
      "1           0.728689           0.712490         0.720674        0.006614   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                1            0.791365            0.781148   \n",
      "1                2            0.819238            0.809153   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.793744          0.788752         0.005464  \n",
      "1            0.815462          0.814618         0.004160  \n"
     ]
    }
   ],
   "source": [
    "parameters_ada = {\n",
    "    'ada__n_estimators': (500,1000),\n",
    "}\n",
    "\n",
    "pipeline_ada = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english') ),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "grid_ada = GridSearchCV(pipeline_ada, parameters_ada, cv = 3)\n",
    "grid_ada.fit(X_train, y_train)\n",
    "\n",
    "results_ada = pd.DataFrame.from_dict(grid_ada.cv_results_)\n",
    "print(results_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       7.158142      0.239082         0.455528        0.089754   \n",
      "1      13.709453      0.998323         0.998519        0.050000   \n",
      "\n",
      "  param_ada__n_estimators                       params  split0_test_score  \\\n",
      "0                     500   {'ada__n_estimators': 500}           0.698989   \n",
      "1                    1000  {'ada__n_estimators': 1000}           0.704452   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.696721           0.695819         0.697177        0.001334   \n",
      "1           0.709290           0.685433         0.699727        0.010296   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                2            0.786719            0.768989   \n",
      "1                1            0.842875            0.835792   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.788963          0.781557         0.008934  \n",
      "1            0.846059          0.841575         0.004291  \n"
     ]
    }
   ],
   "source": [
    "parameters_ada = {\n",
    "    'ada__n_estimators': (500,1000),\n",
    "}\n",
    "\n",
    "pipeline_ada = Pipeline([\n",
    "    ('bow', TfidfVectorizer(stop_words = 'english')) ,\n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "grid_ada = GridSearchCV(pipeline_ada, parameters_ada, cv = 3)\n",
    "grid_ada.fit(X_train, y_train)\n",
    "\n",
    "results_ada = pd.DataFrame.from_dict(grid_ada.cv_results_)\n",
    "print(results_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate best Adaboost model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571956</td>\n",
       "      <td>0.567073</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.641343</td>\n",
       "      <td>0.677239</td>\n",
       "      <td>0.609060</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842613</td>\n",
       "      <td>0.834201</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>2258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.751366</td>\n",
       "      <td>0.751366</td>\n",
       "      <td>0.751366</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.685304</td>\n",
       "      <td>0.692838</td>\n",
       "      <td>0.679060</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.750234</td>\n",
       "      <td>0.749815</td>\n",
       "      <td>0.751366</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.571956   0.567073  0.576923    806.0\n",
       "1             0.641343   0.677239  0.609060    596.0\n",
       "2             0.842613   0.834201  0.851196   2258.0\n",
       "micro avg     0.751366   0.751366  0.751366   3660.0\n",
       "macro avg     0.685304   0.692838  0.679060   3660.0\n",
       "weighted avg  0.750234   0.749815  0.751366   3660.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_ada = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english') ),\n",
    "    ('ada', AdaBoostClassifier(n_estimators = 500))\n",
    "])\n",
    "\n",
    "best_pipeline_ada.fit(X_train, y_train)\n",
    "best_ada_preds = best_pipeline_ada.predict(X_test)\n",
    "\n",
    "cr_best_ada = classification_report(y_test,best_ada_preds,output_dict=True)\n",
    "pd.DataFrame(cr_best_ada).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the pre-trained model \"Vader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "vader_preds_raw = train['text'].map(lambda x: analyser.polarity_scores(x)['compound'])\n",
    "vader_preds = vader_preds_raw.map(lambda x: to_label(x)).tolist()\n",
    "labels = train['airline_sentiment'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402649</td>\n",
       "      <td>0.385205</td>\n",
       "      <td>0.421749</td>\n",
       "      <td>3099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.472926</td>\n",
       "      <td>0.325965</td>\n",
       "      <td>0.861193</td>\n",
       "      <td>2363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.893885</td>\n",
       "      <td>0.487361</td>\n",
       "      <td>9178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.533811</td>\n",
       "      <td>0.533811</td>\n",
       "      <td>0.533811</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.502125</td>\n",
       "      <td>0.535018</td>\n",
       "      <td>0.590101</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.557023</td>\n",
       "      <td>0.694541</td>\n",
       "      <td>0.533811</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.402649   0.385205  0.421749   3099.0\n",
       "1             0.472926   0.325965  0.861193   2363.0\n",
       "2             0.630800   0.893885  0.487361   9178.0\n",
       "micro avg     0.533811   0.533811  0.533811  14640.0\n",
       "macro avg     0.502125   0.535018  0.590101  14640.0\n",
       "weighted avg  0.557023   0.694541  0.533811  14640.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_vader = classification_report(labels,vader_preds,output_dict=True)\n",
    "pd.DataFrame(cr_vader).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the model on my labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Tweet'] = tweets['Tweet'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Tweet'] = tweets['Tweet'].map(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = tweets['Tweet'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tweets['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(map(lambda x: 0 if x == 0.1 else 1,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = best_pipeline_lr.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = list(map(lambda x: 1 if x > 0 else 0,test_preds.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(label,test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(zip(label,test_preds,tweets['Tweet'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results, columns = ['actual','predicted','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Almost that time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruins sign Zdeno Chara to a oneyear contract extension through the 20192020 season worth 2 million plus an additional 175 million in performancebased incentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bruins defenseman Connor Clifton born in Long Branch NJ and raised in Matawan is expected to be in the lineup v the Devils Will mark his first NHL game against New Jersey Should have a nice following tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Records Since Trade Deadline 91 Vegas Golden Knights 102 Tampa Bay Lightning 821 Washington Capitals 721 Carolina Hurricanes 83 Boston Bruins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Bruins look for their third win in a row tonight against New Jersey Tuukka Rask and Marbleheads Cory Schneider are the starting goalie 7pm on NESN BEEEEEE THERRRRRRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruins announce that Lee Stempniak ha been assigned back to Providence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Boston Bruins are 1934 since the AllStar break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Good news Bruins fan Marcus Johansson ha a chance to play tomorrow against the Lightning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruins captain Zdeno Chara had the ultimate Florida man experience  via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The future of Lebanese hockey is in good hand On this picture Antoine Waked Laval Rockets AHL affiliate of the Montreal Canadiens and Karl ElMir Providence Bruins AHL affiliate of the Boston Bruins Rivals on the ice brother off the ice Watch out world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is why it can be so maddening to be an fan at time Tuukka Rask can drive you crazy but hes an excellent goaltender Torey Krug will make mistake find me an offensively gifted D who doesnt but he also brings elite production elite character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bruins out of control right now Patrice Bergeron make it 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Heres a look at Bruins prospect Jakub Lauko dropping the glove and mixing it up in the QMJHL Playoffs against Shawinigan Lauko ha some serious skill and speed but hes also tenacious and brings energy Lauko will be a fan favorite in Boston in no time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The lost The lost The lost All right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>cant miss a matinee game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris Wagner the Mayor of Walpole is the winner of the 201819 Bruins 7th Player Award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stole The Great Larry Birds Shamrocks From The Garden During A Bruins Night Game And Now I Am Going To Disneyland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruins locker room guest this season New England Patriots SB Champs Boston Red Sox WS Champs Connor McGregor 2x UFC Champ Dak Prescott random Bs are buzzing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WIN  with his 3rd hat trick of the season and a regular season careerhigh 5 point in the 63 victory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Why on earth would you scratch Clifton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Reminder Brad Marchand is three point away from being the first Bruin to record 100 point in a single season since Joe Thornton accomplished the feat back in 200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I wa chatting privately w a couple of people in our PatsBruins fam who are struggling One person said they didnt mention their battle because so many others are worse off Another expressed concern over being judgedI am here if any of you need a friend You are NOT alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Puck dropped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OH MY STEEL Penalty shot HAT TRICK The now lead 32 at the end of the 2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>big shocker his bio say patriotsred soxcelticsbruins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personalised Boston Bruins Jersey Throw Pillow Cushion Cover F by RepublicMarketGoods via</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual  predicted  \\\n",
       "11       0          1   \n",
       "15       0          1   \n",
       "20       1          0   \n",
       "22       0          1   \n",
       "23       0          1   \n",
       "27       0          1   \n",
       "30       0          1   \n",
       "32       1          0   \n",
       "40       0          1   \n",
       "41       1          0   \n",
       "44       1          0   \n",
       "47       1          0   \n",
       "50       1          0   \n",
       "53       0          1   \n",
       "54       0          1   \n",
       "62       1          0   \n",
       "63       0          1   \n",
       "66       0          1   \n",
       "67       1          0   \n",
       "69       1          0   \n",
       "73       1          0   \n",
       "79       0          1   \n",
       "80       0          1   \n",
       "85       1          0   \n",
       "98       0          1   \n",
       "99       0          1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                            tweet  \n",
       "11                                                                                                                                                                                                                                                               Almost that time  \n",
       "15                                                                                                               Bruins sign Zdeno Chara to a oneyear contract extension through the 20192020 season worth 2 million plus an additional 175 million in performancebased incentive  \n",
       "20                                                                Bruins defenseman Connor Clifton born in Long Branch NJ and raised in Matawan is expected to be in the lineup v the Devils Will mark his first NHL game against New Jersey Should have a nice following tonight  \n",
       "22                                                                                                                             Best Records Since Trade Deadline 91 Vegas Golden Knights 102 Tampa Bay Lightning 821 Washington Capitals 721 Carolina Hurricanes 83 Boston Bruins  \n",
       "23                                                                                                      The Bruins look for their third win in a row tonight against New Jersey Tuukka Rask and Marbleheads Cory Schneider are the starting goalie 7pm on NESN BEEEEEE THERRRRRRE  \n",
       "27                                                                                                                                                                                                         Bruins announce that Lee Stempniak ha been assigned back to Providence  \n",
       "30                                                                                                                                                                                                                             The Boston Bruins are 1934 since the AllStar break  \n",
       "32                                                                                                                                                                                       Good news Bruins fan Marcus Johansson ha a chance to play tomorrow against the Lightning  \n",
       "40                                                                                                                                                                                                       Bruins captain Zdeno Chara had the ultimate Florida man experience  via  \n",
       "41                    The future of Lebanese hockey is in good hand On this picture Antoine Waked Laval Rockets AHL affiliate of the Montreal Canadiens and Karl ElMir Providence Bruins AHL affiliate of the Boston Bruins Rivals on the ice brother off the ice Watch out world  \n",
       "44                          This is why it can be so maddening to be an fan at time Tuukka Rask can drive you crazy but hes an excellent goaltender Torey Krug will make mistake find me an offensively gifted D who doesnt but he also brings elite production elite character  \n",
       "47                                                                                                                                                                                                                    Bruins out of control right now Patrice Bergeron make it 40  \n",
       "50                    Heres a look at Bruins prospect Jakub Lauko dropping the glove and mixing it up in the QMJHL Playoffs against Shawinigan Lauko ha some serious skill and speed but hes also tenacious and brings energy Lauko will be a fan favorite in Boston in no time  \n",
       "53                                                                                                                                                                                                                                           The lost The lost The lost All right  \n",
       "54                                                                                                                                                                                                                                                      cant miss a matinee game  \n",
       "62                                                                                                                                                                                          Chris Wagner the Mayor of Walpole is the winner of the 201819 Bruins 7th Player Award  \n",
       "63                                                                                                                                                           I Stole The Great Larry Birds Shamrocks From The Garden During A Bruins Night Game And Now I Am Going To Disneyland  \n",
       "66                                                                                                                  Bruins locker room guest this season New England Patriots SB Champs Boston Red Sox WS Champs Connor McGregor 2x UFC Champ Dak Prescott random Bs are buzzing  \n",
       "67                                                                                                                                                                           WIN  with his 3rd hat trick of the season and a regular season careerhigh 5 point in the 63 victory  \n",
       "69                                                                                                                                                                                                                                         Why on earth would you scratch Clifton  \n",
       "73                                                                                                           Reminder Brad Marchand is three point away from being the first Bruin to record 100 point in a single season since Joe Thornton accomplished the feat back in 200203  \n",
       "79  I wa chatting privately w a couple of people in our PatsBruins fam who are struggling One person said they didnt mention their battle because so many others are worse off Another expressed concern over being judgedI am here if any of you need a friend You are NOT alone  \n",
       "80                                                                                                                                                                                                                                                                   Puck dropped  \n",
       "85                                                                                                                                                                                                       OH MY STEEL Penalty shot HAT TRICK The now lead 32 at the end of the 2nd  \n",
       "98                                                                                                                                                                                                                         big shocker his bio say patriotsred soxcelticsbruins  \n",
       "99                                                                                                                                                                                      Personalised Boston Bruins Jersey Throw Pillow Cushion Cover F by RepublicMarketGoods via  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['actual']!=results['predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ring gain near save negotiate phoenix upcoming spring song daily anytime resolution dmed fam fort possible brother ceo announced midnight winter hook jblu hawaii reserve eastern partnership promo allow nashville music conf atlanta rr meant volunteer saw golf photo revenue requires journal mexico grandma carry discount hi australia suggestion dal\n",
      "\n",
      "\n",
      "1: quick compliment thursday view lt3 handled heart wish good sea win world saved snack las fav lady beautiful passbook thnx type incredible star happy enjoy perfect impressed comfortable cool rock appreciate worked loved worry love exceptional loving deserves best sweet thx kudos excited excellent great amazing wonderful thanks awesome thank\n",
      "\n",
      "\n",
      "2: suitcase killing stranded lost 140 feedback ruining telling alternate situation story communication text wont stuck hate error joke crazy unless frustrated solution you havent unacceptable werent frustration lose lie paid fuck half stop unhappy worse hr screwed disappointed hire delayed answer luggage hold hour terrible fix suck rude ridiculous worst\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = best_pipeline_lr.steps[0][1].get_feature_names()\n",
    "for i, class_label in enumerate([0,1,2]):\n",
    "    top = np.argsort(best_pipeline_lr.steps[1][1].coef_[i])[-50:]\n",
    "    print(\"%s: %s\" % (class_label,\" \".join(feature_names[j] for j in top)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 2 test data sets for third party evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch('boston bruins')\\\n",
    "                                           .setSince(\"2019-03-01\")\\\n",
    "                                           .setUntil(\"2019-04-01\")\\\n",
    "                                           .setMaxTweets(100)\\\n",
    "                                           .setTopTweets(True)\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tweets = []\n",
    "for tweet in tweets:\n",
    "    validation_tweets.append(tweet.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tweets = pd.DataFrame(validation_tweets, columns = ['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_x = validation_tweets['tweet'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_x = tweet_x.map(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x = tweet_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_preds = best_pipeline_lr.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_preds = list(map(lambda x: 1 if x > 0 else 0,validation_preds.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tweets['prediction'] = validation_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tweets.to_csv('validation.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = pd.read_csv('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validated.loc[(validated['tester_one']==validated['tester_two']) & (validated['tester_one']==validated['prediction'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validated.loc[(validated['tester_one']==validated['tester_two'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
