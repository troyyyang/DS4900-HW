{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(tweet):\n",
    "    tweet = tweet.split()\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    lemmed = [stemmer.lemmatize(word) for word in tweet]\n",
    "    return ' '.join(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(score):\n",
    "    if score > .05:\n",
    "        return 1\n",
    "    elif score < -.05:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', text)\n",
    "    text = re.sub('@[^\\s]+', '', text)\n",
    "    text = re.sub('#([^\\s]+)', '', text)\n",
    "    text = regex.sub('', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data and doing some preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Tweets_airline.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['airline_sentiment'] = train['airline_sentiment'].replace('neutral', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['airline_sentiment'] = train['airline_sentiment'].replace('positive', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['airline_sentiment'] = train['airline_sentiment'].replace('negative', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].map(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train['airline_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines and parameter grids to search over for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0        0.267267      0.021719         0.067395        0.004660        0.01   \n",
      "1        0.347720      0.010044         0.071187        0.001796        0.01   \n",
      "2        0.440083      0.020647         0.070822        0.001770        0.01   \n",
      "3        0.248199      0.007239         0.073977        0.000933        0.01   \n",
      "4        0.343974      0.008709         0.070973        0.002231         0.1   \n",
      "5        0.326821      0.003346         0.069016        0.003213         0.1   \n",
      "6        0.411722      0.015955         0.082743        0.020205         0.1   \n",
      "7        0.394413      0.027176         0.072666        0.002334         0.1   \n",
      "8        0.371334      0.008866         0.076054        0.002013         0.5   \n",
      "9        0.344479      0.007639         0.067461        0.008484         0.5   \n",
      "10       0.398890      0.005183         0.070382        0.003498         0.5   \n",
      "11       0.457890      0.006487         0.068403        0.006623         0.5   \n",
      "12       0.408728      0.034223         0.063096        0.002776           1   \n",
      "13       0.394026      0.025834         0.075799        0.004960           1   \n",
      "14       0.442008      0.010631         0.073548        0.005210           1   \n",
      "15       0.516801      0.009653         0.071341        0.003046           1   \n",
      "\n",
      "   param_lr__solver                                      params  \\\n",
      "0         newton-cg  {'lr__C': 0.01, 'lr__solver': 'newton-cg'}   \n",
      "1               sag        {'lr__C': 0.01, 'lr__solver': 'sag'}   \n",
      "2              saga       {'lr__C': 0.01, 'lr__solver': 'saga'}   \n",
      "3             lbfgs      {'lr__C': 0.01, 'lr__solver': 'lbfgs'}   \n",
      "4         newton-cg   {'lr__C': 0.1, 'lr__solver': 'newton-cg'}   \n",
      "5               sag         {'lr__C': 0.1, 'lr__solver': 'sag'}   \n",
      "6              saga        {'lr__C': 0.1, 'lr__solver': 'saga'}   \n",
      "7             lbfgs       {'lr__C': 0.1, 'lr__solver': 'lbfgs'}   \n",
      "8         newton-cg   {'lr__C': 0.5, 'lr__solver': 'newton-cg'}   \n",
      "9               sag         {'lr__C': 0.5, 'lr__solver': 'sag'}   \n",
      "10             saga        {'lr__C': 0.5, 'lr__solver': 'saga'}   \n",
      "11            lbfgs       {'lr__C': 0.5, 'lr__solver': 'lbfgs'}   \n",
      "12        newton-cg     {'lr__C': 1, 'lr__solver': 'newton-cg'}   \n",
      "13              sag           {'lr__C': 1, 'lr__solver': 'sag'}   \n",
      "14             saga          {'lr__C': 1, 'lr__solver': 'saga'}   \n",
      "15            lbfgs         {'lr__C': 1, 'lr__solver': 'lbfgs'}   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
      "0            0.626332           0.626332           0.626572         0.626412   \n",
      "1            0.626332           0.626332           0.626572         0.626412   \n",
      "2            0.626332           0.626332           0.626572         0.626412   \n",
      "3            0.626332           0.626332           0.626572         0.626412   \n",
      "4            0.664299           0.667304           0.672225         0.667942   \n",
      "5            0.664299           0.667304           0.672225         0.667942   \n",
      "6            0.664299           0.667304           0.672499         0.668033   \n",
      "7            0.664299           0.667304           0.672225         0.667942   \n",
      "8            0.730128           0.718656           0.729907         0.726230   \n",
      "9            0.730128           0.718656           0.729907         0.726230   \n",
      "10           0.730128           0.718929           0.729907         0.726321   \n",
      "11           0.730128           0.718656           0.729907         0.726230   \n",
      "12           0.751707           0.747337           0.753964         0.751002   \n",
      "13           0.751707           0.747337           0.753964         0.751002   \n",
      "14           0.751707           0.747883           0.753964         0.751184   \n",
      "15           0.751707           0.747883           0.753964         0.751184   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.000113               13            0.626452            0.626452   \n",
      "1         0.000113               13            0.626452            0.626452   \n",
      "2         0.000113               13            0.626452            0.626452   \n",
      "3         0.000113               13            0.626452            0.626452   \n",
      "4         0.003267               10            0.670174            0.668807   \n",
      "5         0.003267               10            0.670174            0.668807   \n",
      "6         0.003387                9            0.670174            0.668807   \n",
      "7         0.003267               10            0.670174            0.668807   \n",
      "8         0.005357                6            0.761579            0.760486   \n",
      "9         0.005357                6            0.761579            0.760486   \n",
      "10        0.005228                5            0.761579            0.760896   \n",
      "11        0.005357                6            0.761579            0.760486   \n",
      "12        0.002751                3            0.827162            0.826889   \n",
      "13        0.002751                3            0.827162            0.826889   \n",
      "14        0.002510                1            0.827845            0.827572   \n",
      "15        0.002510                1            0.827162            0.826889   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             0.626332          0.626412         0.000057  \n",
      "1             0.626332          0.626412         0.000057  \n",
      "2             0.626332          0.626412         0.000057  \n",
      "3             0.626332          0.626412         0.000057  \n",
      "4             0.665938          0.668306         0.001765  \n",
      "5             0.665938          0.668306         0.001765  \n",
      "6             0.665938          0.668306         0.001765  \n",
      "7             0.665938          0.668306         0.001765  \n",
      "8             0.755258          0.759108         0.002759  \n",
      "9             0.755258          0.759108         0.002759  \n",
      "10            0.755395          0.759290         0.002769  \n",
      "11            0.755258          0.759108         0.002759  \n",
      "12            0.823545          0.825866         0.001644  \n",
      "13            0.823545          0.825866         0.001644  \n",
      "14            0.824092          0.826503         0.001709  \n",
      "15            0.823545          0.825866         0.001644  \n"
     ]
    }
   ],
   "source": [
    "parameters_lr = {\n",
    "    'lr__C': (.01,0.1, 0.5,1),\n",
    "    'lr__solver' : ('newton-cg', 'sag', 'saga', 'lbfgs')\n",
    "}\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('lr', LogisticRegression(max_iter = 400))\n",
    "])\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, parameters_lr, cv = 3)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "results_lr = pd.DataFrame.from_dict(grid_lr.cv_results_)\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0        0.220076      0.005778         0.046210        0.001243        0.01   \n",
      "1        0.216421      0.024102         0.046220        0.003406        0.01   \n",
      "2        0.486021      0.025301         0.046868        0.002826        0.01   \n",
      "3        0.136303      0.002860         0.046209        0.001695        0.01   \n",
      "4        0.269281      0.005339         0.044215        0.000470         0.1   \n",
      "5        0.228721      0.003080         0.044223        0.001256         0.1   \n",
      "6        0.425186      0.013513         0.047561        0.005245         0.1   \n",
      "7        0.198793      0.027383         0.051871        0.004318         0.1   \n",
      "8        0.315148      0.017031         0.043905        0.000801         0.5   \n",
      "9        0.307835      0.026311         0.043882        0.000814         0.5   \n",
      "10       0.640630      0.051647         0.046867        0.004214         0.5   \n",
      "11       0.233376      0.001628         0.044215        0.001244         0.5   \n",
      "12       0.338105      0.002926         0.044215        0.000473           1   \n",
      "13       0.378985      0.001627         0.045546        0.001242           1   \n",
      "14       0.771614      0.008543         0.043546        0.000938           1   \n",
      "15       0.274590      0.007895         0.044869        0.000801           1   \n",
      "\n",
      "   param_lr__solver                                      params  \\\n",
      "0         newton-cg  {'lr__C': 0.01, 'lr__solver': 'newton-cg'}   \n",
      "1               sag        {'lr__C': 0.01, 'lr__solver': 'sag'}   \n",
      "2              saga       {'lr__C': 0.01, 'lr__solver': 'saga'}   \n",
      "3             lbfgs      {'lr__C': 0.01, 'lr__solver': 'lbfgs'}   \n",
      "4         newton-cg   {'lr__C': 0.1, 'lr__solver': 'newton-cg'}   \n",
      "5               sag         {'lr__C': 0.1, 'lr__solver': 'sag'}   \n",
      "6              saga        {'lr__C': 0.1, 'lr__solver': 'saga'}   \n",
      "7             lbfgs       {'lr__C': 0.1, 'lr__solver': 'lbfgs'}   \n",
      "8         newton-cg   {'lr__C': 0.5, 'lr__solver': 'newton-cg'}   \n",
      "9               sag         {'lr__C': 0.5, 'lr__solver': 'sag'}   \n",
      "10             saga        {'lr__C': 0.5, 'lr__solver': 'saga'}   \n",
      "11            lbfgs       {'lr__C': 0.5, 'lr__solver': 'lbfgs'}   \n",
      "12        newton-cg     {'lr__C': 1, 'lr__solver': 'newton-cg'}   \n",
      "13              sag           {'lr__C': 1, 'lr__solver': 'sag'}   \n",
      "14             saga          {'lr__C': 1, 'lr__solver': 'saga'}   \n",
      "15            lbfgs         {'lr__C': 1, 'lr__solver': 'lbfgs'}   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
      "0            0.668943           0.667304           0.671952         0.669399   \n",
      "1            0.668943           0.667304           0.671952         0.669399   \n",
      "2            0.669489           0.667850           0.672225         0.669854   \n",
      "3            0.668943           0.667304           0.671952         0.669399   \n",
      "4            0.747610           0.736411           0.740842         0.741621   \n",
      "5            0.747610           0.736411           0.740842         0.741621   \n",
      "6            0.748429           0.738050           0.741662         0.742714   \n",
      "7            0.747610           0.736411           0.741115         0.741712   \n",
      "8            0.766184           0.763179           0.763532         0.764299   \n",
      "9            0.766184           0.763179           0.763532         0.764299   \n",
      "10           0.767277           0.763179           0.762985         0.764481   \n",
      "11           0.766184           0.763179           0.763532         0.764299   \n",
      "12           0.767004           0.761814           0.764625         0.764481   \n",
      "13           0.767004           0.761814           0.764899         0.764572   \n",
      "14           0.766730           0.762360           0.765172         0.764754   \n",
      "15           0.767004           0.761814           0.764625         0.764481   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.001925               14            0.671540            0.672906   \n",
      "1         0.001925               14            0.671540            0.672906   \n",
      "2         0.001805               13            0.671676            0.673179   \n",
      "3         0.001925               14            0.671540            0.672906   \n",
      "4         0.004606               11            0.778932            0.778385   \n",
      "5         0.004606               11            0.778932            0.778385   \n",
      "6         0.004303                9            0.780161            0.778932   \n",
      "7         0.004592               10            0.778932            0.778385   \n",
      "8         0.001341                6            0.839049            0.840415   \n",
      "9         0.001341                6            0.839049            0.840552   \n",
      "10        0.001979                3            0.838639            0.840962   \n",
      "11        0.001341                6            0.839049            0.840415   \n",
      "12        0.002121                3            0.856265            0.859817   \n",
      "13        0.002132                2            0.856265            0.859817   \n",
      "14        0.001809                1            0.856538            0.859954   \n",
      "15        0.002121                3            0.856265            0.859817   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             0.672084          0.672177         0.000562  \n",
      "1             0.672084          0.672177         0.000562  \n",
      "2             0.672494          0.672450         0.000614  \n",
      "3             0.672084          0.672177         0.000562  \n",
      "4             0.771101          0.776139         0.003570  \n",
      "5             0.771101          0.776139         0.003570  \n",
      "6             0.772057          0.777050         0.003566  \n",
      "7             0.771101          0.776139         0.003570  \n",
      "8             0.837613          0.839026         0.001144  \n",
      "9             0.837613          0.839071         0.001200  \n",
      "10            0.837476          0.839026         0.001449  \n",
      "11            0.837613          0.839026         0.001144  \n",
      "12            0.854411          0.856831         0.002243  \n",
      "13            0.854411          0.856831         0.002243  \n",
      "14            0.854548          0.857013         0.002232  \n",
      "15            0.854548          0.856876         0.002194  \n"
     ]
    }
   ],
   "source": [
    "parameters_lr = {\n",
    "    'lr__C': (.01,0.1, 0.5,1),\n",
    "    'lr__solver' : ('newton-cg', 'sag', 'saga', 'lbfgs')\n",
    "}\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english')  ),\n",
    "    ('lr', LogisticRegression(max_iter = 400))\n",
    "])\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, parameters_lr, cv = 3)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "results_lr = pd.DataFrame.from_dict(grid_lr.cv_results_)\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate best LR model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577653</td>\n",
       "      <td>0.631336</td>\n",
       "      <td>0.532383</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672880</td>\n",
       "      <td>0.744330</td>\n",
       "      <td>0.613946</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.862769</td>\n",
       "      <td>0.824485</td>\n",
       "      <td>0.904783</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.779508</td>\n",
       "      <td>0.779508</td>\n",
       "      <td>0.779508</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.704434</td>\n",
       "      <td>0.733384</td>\n",
       "      <td>0.683704</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.772123</td>\n",
       "      <td>0.770867</td>\n",
       "      <td>0.779508</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.577653   0.631336  0.532383    772.0\n",
       "1             0.672880   0.744330  0.613946    588.0\n",
       "2             0.862769   0.824485  0.904783   2300.0\n",
       "micro avg     0.779508   0.779508  0.779508   3660.0\n",
       "macro avg     0.704434   0.733384  0.683704   3660.0\n",
       "weighted avg  0.772123   0.770867  0.779508   3660.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_lr = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english')  ),\n",
    "    ('lr', LogisticRegression( C = 1, solver = 'saga',max_iter = 400))\n",
    "])\n",
    "\n",
    "best_pipeline_lr.fit(X_train, y_train)\n",
    "best_lr_preds = best_pipeline_lr.predict(X_test)\n",
    "\n",
    "cr_best_lr = classification_report(y_test,best_lr_preds,output_dict=True)\n",
    "pd.DataFrame(cr_best_lr).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines and parameter grids to search over for naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.170221      0.015330         0.071708        0.003099   \n",
      "1       0.133043      0.001019         0.067854        0.009916   \n",
      "2       0.157123      0.008614         0.070896        0.003583   \n",
      "3       0.165459      0.008402         0.076485        0.002102   \n",
      "4       0.162114      0.005817         0.073622        0.005198   \n",
      "5       0.163985      0.008150         0.070206        0.002879   \n",
      "\n",
      "  param_nb__alpha param_nb__fit_prior  \\\n",
      "0           1e-05                True   \n",
      "1           1e-05               False   \n",
      "2             0.5                True   \n",
      "3             0.5               False   \n",
      "4               1                True   \n",
      "5               1               False   \n",
      "\n",
      "                                         params  split0_test_score  \\\n",
      "0   {'nb__alpha': 1e-05, 'nb__fit_prior': True}           0.718383   \n",
      "1  {'nb__alpha': 1e-05, 'nb__fit_prior': False}           0.701175   \n",
      "2     {'nb__alpha': 0.5, 'nb__fit_prior': True}           0.701994   \n",
      "3    {'nb__alpha': 0.5, 'nb__fit_prior': False}           0.756897   \n",
      "4       {'nb__alpha': 1, 'nb__fit_prior': True}           0.671948   \n",
      "5      {'nb__alpha': 1, 'nb__fit_prior': False}           0.750341   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.721934           0.716238         0.718852        0.002349   \n",
      "1           0.705818           0.701203         0.702732        0.002182   \n",
      "2           0.696804           0.708037         0.702277        0.004590   \n",
      "3           0.752253           0.761618         0.756922        0.003823   \n",
      "4           0.671674           0.677146         0.673588        0.002517   \n",
      "5           0.744059           0.759158         0.751184        0.006192   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                3            0.918568            0.920754   \n",
      "1                4            0.932368            0.931002   \n",
      "2                5            0.814456            0.816095   \n",
      "3                1            0.888509            0.884410   \n",
      "4                6            0.732750            0.738079   \n",
      "5                2            0.860910            0.861593   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.918328          0.919217         0.001091  \n",
      "1            0.931986          0.931785         0.000576  \n",
      "2            0.812756          0.814436         0.001363  \n",
      "3            0.884048          0.885656         0.002023  \n",
      "4            0.733679          0.734836         0.002324  \n",
      "5            0.859738          0.860747         0.000766  \n"
     ]
    }
   ],
   "source": [
    "parameters_nb = {\n",
    "    'nb__alpha': (0.00001, 0.5, 1),\n",
    "    'nb__fit_prior' : (True, False)\n",
    "}\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "grid_nb = GridSearchCV(pipeline_nb, parameters_nb, cv = 3)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "results_nb = pd.DataFrame.from_dict(grid_nb.cv_results_)\n",
    "print(results_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.105043      0.004174         0.050863        0.005353   \n",
      "1       0.107389      0.012948         0.044881        0.001629   \n",
      "2       0.109699      0.009875         0.050862        0.004329   \n",
      "3       0.107703      0.011318         0.050534        0.009402   \n",
      "4       0.108045      0.008632         0.047216        0.004713   \n",
      "5       0.097074      0.000941         0.044880        0.001411   \n",
      "\n",
      "  param_nb__alpha param_nb__fit_prior  \\\n",
      "0           1e-05                True   \n",
      "1           1e-05               False   \n",
      "2             0.5                True   \n",
      "3             0.5               False   \n",
      "4               1                True   \n",
      "5               1               False   \n",
      "\n",
      "                                         params  split0_test_score  \\\n",
      "0   {'nb__alpha': 1e-05, 'nb__fit_prior': True}           0.737777   \n",
      "1  {'nb__alpha': 1e-05, 'nb__fit_prior': False}           0.715105   \n",
      "2     {'nb__alpha': 0.5, 'nb__fit_prior': True}           0.745971   \n",
      "3    {'nb__alpha': 0.5, 'nb__fit_prior': False}           0.714832   \n",
      "4       {'nb__alpha': 1, 'nb__fit_prior': True}           0.748429   \n",
      "5      {'nb__alpha': 1, 'nb__fit_prior': False}           0.714832   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.729309           0.738928         0.735337        0.004289   \n",
      "1           0.706364           0.716512         0.712659        0.004489   \n",
      "2           0.740508           0.746309         0.744262        0.002659   \n",
      "3           0.711281           0.719519         0.715209        0.003373   \n",
      "4           0.740508           0.749863         0.746266        0.004114   \n",
      "5           0.714013           0.717059         0.715301        0.001287   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                3            0.818418            0.827026   \n",
      "1                6            0.805848            0.810766   \n",
      "2                2            0.810766            0.814865   \n",
      "3                5            0.782347            0.786173   \n",
      "4                1            0.800246            0.807351   \n",
      "5                4            0.774149            0.780025   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.823819          0.823087         0.003552  \n",
      "1            0.812893          0.809836         0.002950  \n",
      "2            0.810844          0.812159         0.001914  \n",
      "3            0.789402          0.785974         0.002883  \n",
      "4            0.806474          0.804690         0.003163  \n",
      "5            0.779432          0.777869         0.002641  \n"
     ]
    }
   ],
   "source": [
    "parameters_nb = {\n",
    "    'nb__alpha': (0.00001, 0.5, 1),\n",
    "    'nb__fit_prior' : (True, False)\n",
    "}\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english') ),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "grid_nb = GridSearchCV(pipeline_nb, parameters_nb, cv = 3)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "results_nb = pd.DataFrame.from_dict(grid_nb.cv_results_)\n",
    "print(results_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate best NB model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537160</td>\n",
       "      <td>0.621806</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644007</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.859798</td>\n",
       "      <td>0.818718</td>\n",
       "      <td>0.905217</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.766940</td>\n",
       "      <td>0.766940</td>\n",
       "      <td>0.766940</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.680321</td>\n",
       "      <td>0.706590</td>\n",
       "      <td>0.663420</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.757076</td>\n",
       "      <td>0.754776</td>\n",
       "      <td>0.766940</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.537160   0.621806  0.472798    772.0\n",
       "1             0.644007   0.679245  0.612245    588.0\n",
       "2             0.859798   0.818718  0.905217   2300.0\n",
       "micro avg     0.766940   0.766940  0.766940   3660.0\n",
       "macro avg     0.680321   0.706590  0.663420   3660.0\n",
       "weighted avg  0.757076   0.754776  0.766940   3660.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('nb', MultinomialNB(alpha = .5, fit_prior = False))\n",
    "])\n",
    "\n",
    "best_pipeline_nb.fit(X_train, y_train)\n",
    "best_nb_preds = best_pipeline_nb.predict(X_test)\n",
    "\n",
    "cr_best_nb = classification_report(y_test,best_nb_preds,output_dict=True)\n",
    "pd.DataFrame(cr_best_nb).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipelines and parameter grids to search over for adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       1.867351      0.066080         0.303191        0.023974   \n",
      "1       3.578128      0.164715         0.525573        0.010946   \n",
      "\n",
      "  param_ada__n_estimators                       params  split0_test_score  \\\n",
      "0                     500   {'ada__n_estimators': 500}           0.733406   \n",
      "1                    1000  {'ada__n_estimators': 1000}           0.717290   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.721661           0.737288         0.730783        0.006644   \n",
      "1           0.707184           0.722253         0.715574        0.006270   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                1            0.795191            0.793005   \n",
      "1                2            0.809673            0.808444   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.792953          0.793716         0.001043  \n",
      "1            0.811937          0.810018         0.001447  \n"
     ]
    }
   ],
   "source": [
    "parameters_ada = {\n",
    "    'ada__n_estimators': (500,1000),\n",
    "}\n",
    "\n",
    "pipeline_ada = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english') ),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "grid_ada = GridSearchCV(pipeline_ada, parameters_ada, cv = 3)\n",
    "grid_ada.fit(X_train, y_train)\n",
    "\n",
    "results_ada = pd.DataFrame.from_dict(grid_ada.cv_results_)\n",
    "print(results_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       4.086084      0.071377         0.289548        0.000478   \n",
      "1       8.290173      0.375760         0.556179        0.005446   \n",
      "\n",
      "  param_ada__n_estimators                       params  split0_test_score  \\\n",
      "0                     500   {'ada__n_estimators': 500}           0.706911   \n",
      "1                    1000  {'ada__n_estimators': 1000}           0.699536   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.702540           0.691088         0.700182        0.006671   \n",
      "1           0.699262           0.703390         0.700729        0.001884   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                2            0.779751            0.782347   \n",
      "1                1            0.838639            0.841372   \n",
      "\n",
      "   split2_train_score  mean_train_score  std_train_score  \n",
      "0            0.777110          0.779736         0.002138  \n",
      "1            0.834062          0.838024         0.003016  \n"
     ]
    }
   ],
   "source": [
    "parameters_ada = {\n",
    "    'ada__n_estimators': (500,1000),\n",
    "}\n",
    "\n",
    "pipeline_ada = Pipeline([\n",
    "    ('bow', TfidfVectorizer(stop_words = 'english')) ,\n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "grid_ada = GridSearchCV(pipeline_ada, parameters_ada, cv = 3)\n",
    "grid_ada.fit(X_train, y_train)\n",
    "\n",
    "results_ada = pd.DataFrame.from_dict(grid_ada.cv_results_)\n",
    "print(results_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate best NB model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.540506</td>\n",
       "      <td>0.528465</td>\n",
       "      <td>0.553109</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.628311</td>\n",
       "      <td>0.678501</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833154</td>\n",
       "      <td>0.825160</td>\n",
       "      <td>0.841304</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.739344</td>\n",
       "      <td>0.739344</td>\n",
       "      <td>0.739344</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.667324</td>\n",
       "      <td>0.677375</td>\n",
       "      <td>0.659816</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.738517</td>\n",
       "      <td>0.739017</td>\n",
       "      <td>0.739344</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.540506   0.528465  0.553109    772.0\n",
       "1             0.628311   0.678501  0.585034    588.0\n",
       "2             0.833154   0.825160  0.841304   2300.0\n",
       "micro avg     0.739344   0.739344  0.739344   3660.0\n",
       "macro avg     0.667324   0.677375  0.659816   3660.0\n",
       "weighted avg  0.738517   0.739017  0.739344   3660.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_ada = Pipeline([\n",
    "    ('bow',  CountVectorizer(max_features=5000, min_df=5, max_df=0.9, stop_words='english') ),\n",
    "    ('ada', AdaBoostClassifier(n_estimators = 500))\n",
    "])\n",
    "\n",
    "best_pipeline_ada.fit(X_train, y_train)\n",
    "best_ada_preds = best_pipeline_ada.predict(X_test)\n",
    "\n",
    "cr_best_ada = classification_report(y_test,best_ada_preds,output_dict=True)\n",
    "pd.DataFrame(cr_best_ada).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the pre-trained model \"Vader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "vader_preds_raw = train['text'].map(lambda x: analyser.polarity_scores(x)['compound'])\n",
    "vader_preds = vader_preds_raw.map(lambda x: to_label(x)).tolist()\n",
    "labels = train['airline_sentiment'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5338114754098361"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(labels, vader_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402649</td>\n",
       "      <td>0.385205</td>\n",
       "      <td>0.421749</td>\n",
       "      <td>3099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.472926</td>\n",
       "      <td>0.325965</td>\n",
       "      <td>0.861193</td>\n",
       "      <td>2363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.893885</td>\n",
       "      <td>0.487361</td>\n",
       "      <td>9178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.533811</td>\n",
       "      <td>0.533811</td>\n",
       "      <td>0.533811</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.502125</td>\n",
       "      <td>0.535018</td>\n",
       "      <td>0.590101</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.557023</td>\n",
       "      <td>0.694541</td>\n",
       "      <td>0.533811</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "0             0.402649   0.385205  0.421749   3099.0\n",
       "1             0.472926   0.325965  0.861193   2363.0\n",
       "2             0.630800   0.893885  0.487361   9178.0\n",
       "micro avg     0.533811   0.533811  0.533811  14640.0\n",
       "macro avg     0.502125   0.535018  0.590101  14640.0\n",
       "weighted avg  0.557023   0.694541  0.533811  14640.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_vader = classification_report(labels,vader_preds,output_dict=True)\n",
    "pd.DataFrame(cr_vader).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
